{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Cindy Wang\"\n",
    "__version__ = \"Alibaba August 2018\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The following packages are required:\n",
    "```\n",
    "numpy==1.14.0\n",
    "scipy==1.0.0\n",
    "scikit-learn >= 0.19.1\n",
    "jupyter==1.0.0\n",
    "```\n",
    "\n",
    "You can paste these into a `requirements.txt` file and run\n",
    "`pip install -r requirements.txt`. You will also need to install Tensorflow by following the instructions on the [website](https://www.tensorflow.org/install/).\n",
    "\n",
    "## Running the notebook\n",
    "Navigate to your notebooks directory (wherever this file is located) and run `jupyter notebook --port 5656` to start the notebook server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs\n",
    "\n",
    "Recall the most basic artifical neural network, an MLP (multi-layer perceptron, or feed-forward neural network). Each layer of this network has its own weights $W$, biases $b$, and activation function $f$. These are applied, then the activations are sent to the next layer. The following set of equations describes an $N$-layer MLP:\n",
    "\n",
    "$$\\begin{align} \n",
    "A_0 : h_0 &= f(W_0 x + b_0) \\\\ \n",
    "A_1 : h_1 &= f(W_1 h_0 + b_1) \\\\ \n",
    "&\\dots \\\\\n",
    "A_N : h_N &= f(W_N h_{N-1} + b_N)\n",
    "\\end{align}$$\n",
    "\n",
    "Now imagine that instead of a single vector input, we have a sequence of vectors. Our objective is now to capture relationships between successive inputs. We can achieve this by feeding **successive inputs** to **successive hidden layers**:\n",
    "![rnn1](img/rnn1.png)\n",
    "\n",
    "In a typical MLP, the weights $W$ and biases $b$ in each layer are independent. However, if we want the neural network layers $A$ to remember the state of previous inputs when reading the next input in the sequence, we can roll the $A_n$s into a single layer $A$. At each time step, the inputs are supplied to the same network layer $A$ with a single set of weights and biases -- this $A$ is referred to as the **RNN cell**. The outputs of the RNN are just the hidden states $h_t$ at each time step. This gives us the classic RNN:\n",
    "![rnn2](img/rnn2.png)\n",
    "\n",
    "You might have noticed that unlike the MLP hidden layer which has a single input, an RNN cell has two inputs: $x_t$ and the previous hidden state $h_{t-1}$. Therefore, we replace the weight matrix $W$ with two different matrices $U$ and $V$, which are applied to $x_t$ and $h_{t-1}$ respectively. Notice the differences between the MLP and RNN layers:\n",
    "\n",
    "$$\\begin{align*} \n",
    "& \\textbf{MLP: } & & \\textbf{RNN: }\\\\\n",
    "A_0 : h_0 &= f(W_0 x + b_0) &  h_0 &= f(Vx_0 + b)\\\\ \n",
    "A_1 : h_1 &= f(W_1 h_0 + b_1) & h_1 &= f(Uh_0 + Vx_1 + b)\\\\ \n",
    "& \\dots & &\\dots\\\\\n",
    "A_N : h_N &= f(W_N h_{N-1} + b_N) & h_N &= f(Uh_{N-1} + Vx_N + b)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem with RNNs\n",
    "\n",
    "We now have a good understanding of the basic vanilla RNN. However, RNNs of the form described above aren't used very often in the real world. Why? The issue is something called the **vanishing gradient problem**. \n",
    "\n",
    "In practice, we want our RNN to be able to handle a large number of time steps and remember inputs across long distances. For example, consider the following sentences:\n",
    "\n",
    "1. \"Jane walked into the room. John walked in too. Jane said hi to ___\"\n",
    "2. \"Jane walked into the room. John walked in too. It was late in the day, and everyone was walking home after a long day at work. Jane said hi to ___\"\n",
    "\n",
    "Clearly, the next word in both sentences should be \"John.\" However, a vanilla RNN is less likely to correctly predict the next word in Sentence 2. This is because of the way RNN weights are updated during training via a method called **backpropagation**: the training updates to the weights gradually vanish as they propagate to earlier time steps.\n",
    "\n",
    "Let us briefly discuss the mathematical reasoning behind this. Consider the equations for an RNN with $N$ time steps (note that we will leave out the biases from here on for clarity):\n",
    "\n",
    "$$\\begin{align}\n",
    "h_0 &= f(Vx_0)\\\\ \n",
    "h_1 &= f(Uh_0 + Vx_1)\\\\ \n",
    "& \\dots \\\\\n",
    "h_N &= f(Uh_{N-1} + Vx_N)\\\\\n",
    "out &= output\\_layer(h_N)\\\\\n",
    "J &= loss\\_fn(out, label)\n",
    "\\end{align}$$\n",
    "\n",
    "Essentially, backpropagation involves calculating the gradient (partial derivative) of the total error with respect to each of the weights in the network so that we can update them using gradient descent. Say we want to find the gradient with respect to the weight matrix $U$. You might remember from calculus that we can combine partial derivatives using the chain rule. The gradient of the error $J$ with respect to $U$ then looks something like:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial U} = \\frac{\\partial J}{\\partial out}\\frac{\\partial out}{\\partial h_N}\\frac{\\partial h_N}{\\partial h_{N-1}} \\dots \\frac{\\partial h_1}{\\partial h_0}\\frac{\\partial h_0}{\\partial U}$$\n",
    "\n",
    "The vanishing gradient problem emerges as $N$ increases, since each partial gradient term involves calculating the gradient of the activation function $f$. Consider the plot below of the gradient for $f=\\sigma$, the sigmoid function:\n",
    "\n",
    "![sigmoid gradient](img/Sigmoid-gradient.png)\n",
    "\n",
    "You can observe that the values of the gradient $f'(x)$ (shown in orange) are always <0.25 and become very small when $f(x)$ is close to 0 or 1. In order to get $\\frac{\\partial J}{\\partial V}$, we need to multiply several such gradients together. The resulting gradient becomes close to zero, or \"vanishes.\" As a result, our network is not able to update its weights across a large number of time steps.\n",
    "\n",
    "This is only a rough sketch of what goes on during backpropagation, but it is sufficient to understand why we need something more complex than a vanilla RNN. For a full explanation of the vanishing and exploding gradient problem, the original paper is by [Bengio et al., 1994](https://ieeexplore.ieee.org/document/279181/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMs\n",
    "\n",
    "The LSTM, or long short-term memory network, is a specialized RNN cell that has a few advantages over the vanilla RNN cell:\n",
    "- It keep tracks of an *internal memory state* in addition to a new *candidate state* at each time step\n",
    "- It uses gates to control how much of the internal state to forget and how much of the candidate state to add\n",
    "- It can remember long-term memory\n",
    "- It reduces the vanishing gradient problem\n",
    "\n",
    "As a result, LSTMs are used widely in practical settings and are a strong baseline for many sequence-related machine learning tasks. We will now take a closer look at how they work.\n",
    "\n",
    "Notice that the LSTM is a generalized form of the vanilla RNN. They have the same chainlike structure, but the LSTM cell contains more layers, all of which interact together:.\n",
    "\n",
    "**RNN:** ![rnn3](img\\rnn3.png) \n",
    "**LSTM:** ![lstm1](img\\lstm1.png) \n",
    "\n",
    "Without worrying too much about the variable names for now, compare the equations for a cell at timestep $t$:\n",
    "\n",
    "\\begin{aligned}\n",
    "    & \\textbf{RNN: }(f = tanh) & & \\textbf{LSTM: }\\\\\n",
    "    h_{t} &= \\tanh\\big(Uh_{t-1} + Vx_{t}\\big) & \\tilde{C}_{t} &= \\tanh\\big(U^{g}h_{t-1}+V^{g}x_{t}\\big) \\\\\n",
    "    && f_{t} & =\\sigma\\big(U^{f}h_{t-1}+V^{f}x_{t}\\big) \\\\\n",
    "    && i_{t} & =\\sigma\\big(U^{i}h_{t-1}+V^{i}x_{t}\\big) \\\\\n",
    "    && o_{t} & =\\sigma\\big(U^{o}h_{t-1}+V^{o}x_{t}\\big) \\\\\n",
    "    && C_{t} & =\\sigma\\big(f_{t}\\ast C_{t-1}+i_{t}\\ast\\tilde{C}_{t}\\big) \\\\\n",
    "    && h_{t} & =\\tanh(C_{t})\\ast o_{t}\n",
    "\\end{aligned}\n",
    "\n",
    "We see that the LSTM candidate state $\\tilde{C}_{t}$, is identical to the RNN hidden state $h_t$! This is not a coincidence. While a vanilla RNN directly returns this value as its hidden state, the LSTM combines $\\tilde{C}_{t}$ with 4 other values -- $i_t, f_t, o_t, C_t$ -- in order to get its hidden state.\n",
    "\n",
    "First, we explain what each of these variables mean:\n",
    "\n",
    "### States\n",
    "- cell state $C_t$: The internal memory of the LSTM. It gets updated with linear modifications at each step.\n",
    "- candidate state $\\tilde{C}_{t}$: The \"new\" state at each time step. A portion of this is saved to the cell state.\n",
    "- hidden state $h_{t}$: The output of the LSTM.\n",
    "\n",
    "### Gates\n",
    "A gate consists of a feed-forward layer with a sigmoid activation. It takes $h_{t-1}$ and $x_t$ as inputs and outputs a number between 0 and 1 for each state dimension. These numbers denote how much information to let through the gate.\n",
    "- forget gate $f_t$: What part of the previous cell state $C_{t-1}$ to retain.\n",
    "- input gate $i_t$: What part of the candidate state $\\tilde{C}_{t}$ to add.\n",
    "- output gate $o_t$: What part of the cell state $C_{t}$ to output.\n",
    "\n",
    "## Step-by-step\n",
    "Next, we walk through the LSTM equations step by step. The inputs to the cell are the previous cell state $C_{t-1}$, the previous hidden state $h_{t-1}$, and the input vector $x_t$ (i.e. the $t$th word in the sequence). \n",
    "\n",
    "#### Retain old info\n",
    "Our first step is to figure out what information to retain from the previous cell state. The forget gate $f_{t}$ looks at $h_{t-1}$ and $x_t$ and outputs a number between 0 and 1 for each dimension of $C_{t-1}$. A 1 means to completely retain the old state and a 0 means to completely throw it away. We then multiply $f_{t}$ pointwise with $C_{t-1}$ to get the previous state's contribution.\n",
    "\n",
    "\\begin{aligned}\n",
    "f_{t} &=\\sigma\\big(U^{f}h_{t-1}+V^{f}x_{t}\\big)\\\\\n",
    "old\\_info_t &= f_{t}\\ast C_{t-1}\n",
    "\\end{aligned}\n",
    "\n",
    "#### Add new info\n",
    "Our next step to do similar calculations to find the contribution of new information. We calculate the candidate state $\\tilde{C}_{t}$ (which, as we noticed before, is same as finding the vanilla RNN hidden state). We then calculate the input gate $i_t$ and pointwise multiply the two to get the candidate state's contribution.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\tilde{C}_{t} &= \\tanh\\big(U^{g}h_{t-1}+V^{g}x_{t}\\big)\\\\\n",
    "i_{t} &= \\sigma\\big(U^{i}h_{t-1}+V^{i}x_{t}\\big)\\\\\n",
    "new\\_info_t &= i_{t}\\ast\\tilde{C}_{t}\n",
    "\\end{aligned}\n",
    "\n",
    "#### Combine\n",
    "Now that we have the previous cell state and current candidate state's contributions, we can combine them to update the cell state.\n",
    "\n",
    "![lstm3-focus-C](img\\LSTM3-focus-C.png)\n",
    "\n",
    "\\begin{aligned}\n",
    "C_{t} &= \\sigma\\big(old\\_info_t + new\\_info_t) \\\\\n",
    "&= \\sigma\\big(f_{t}\\ast C_{t-1}+i_{t}\\ast\\tilde{C}_{t}\\big) \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "#### Output\n",
    "Finally, we need to decide what part of this cell state we actually want to output as $h_t$. The reason that we do this instead of directly outputting $C_t$ is because it allows us to selectively output relevant information. Take for example translation to English: if the current word is a noun, we may want to output whether it is singular or plural so we know what form a verb should take if it comes next.\n",
    "\n",
    "For the output, we apply tanh to the cell state (to constrain the values between -1 and 1), calculate the output gate $o_t$, and pointwise multiply to get $h_t$.\n",
    "\n",
    "![lstm3-focus-o](img\\LSTM3-focus-o.png)\n",
    "\n",
    "$$o_{t} =\\sigma\\big(U^{o}h_{t-1}+V^{o}x_{t}\\big)$$\n",
    "$$h_{t} =\\tanh(C_{t})\\ast o_{t}$$\n",
    "\n",
    "Here is a diagram of the entire LSTM cell with labeled components for reference.\n",
    "![lstm2](img\\lstm2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing LSTMs in Tensorflow\n",
    "\n",
    "We just took the time to explain the LSTM equations, but in practice you will rarely have to declare the weight matrices and operations yourself. Instead, Tensorflow provides an interface to declare a generic RNN with your choice of cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units) # Can also be RNN, GRU, or custom\n",
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, inputs) # [h_0 ... h_N], (C_N, h_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some additional details to actually getting an LSTM up and running in Tensorflow, so we will now go though a full working example with Tensorflow code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Encoder-Decoder: A simple working example\n",
    "\n",
    "## Background\n",
    "\n",
    "### Sequence-to-Sequence\n",
    "For many NLP tasks, the output is a classification:\n",
    "- Sentiment Analysis\n",
    "    - **in:** \"That was a good movie\"\n",
    "    - **out:** [negative, neutral, **positive**]\n",
    "- Natural Language Inference\n",
    "    - **in:** (\"A black race car starts up in front of a crowd of people.\", \"A man is driving down a lonely road.\")\n",
    "    - **out:** [entailment, neutral, **contradiction**]\n",
    "\n",
    "However, there are some tasks that where the output is a sequence and must be generated instead of selected. *Sequence-to-sequence* describes a class of models built for tasks where the input and output are both sequences. These typically require more complex modeling to capture an additional dimension of information.\n",
    "- Machine Translation\n",
    "    - **in:** \"Do you like to play badminton?\"\n",
    "    - **out:** \"你喜欢打羽毛球吗?\"\n",
    "- Sequence Labeling\n",
    "    - **in:** \n",
    "    `\"John  lives in New   York  and works for the European Union\"`\n",
    "    - **out:** \n",
    "    `B-PER O     O  B-LOC I-LOC O   O     O   O   B-ORG    I-ORG`\n",
    "- Video Captioning\n",
    "\n",
    "### Encoder-Decoder\n",
    "*Encoder-decoder* describes a type of model architecture where the entire input is first *encoded* into a single vector, then decoded into the desired output. Many sequence-to-sequence models have this structure, which is useful for tasks with variable length outputs and/or where the entire input is needed in order to generate the output.\n",
    "- Question Answering\n",
    "    - **in:** \n",
    "        - P: \" Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals **within a cloud**.\"\n",
    "        - Q: \"Where do water droplets collide with ice crystals to form precipitation?\"\n",
    "    - **out:** \n",
    "        - A: **within a cloud**\n",
    "- Text Summarization\n",
    "    - **in:** \"Alice and Bob took the train to visit the zoo. They saw a baby giraffe, a lion, and a flock of colorful tropical birds.\n",
    "    - **out:** \"Alice and Bob visited the zoo and saw animals and birds.\"\n",
    "\n",
    "## Task\n",
    "We will go through a basic example that involves feeding a sequence of IDs (numbers) into an LSTM one at a time. (For NLP, these IDs would be the IDs of words in the vocabulary.) Our goal is for the network to echo back a partial or full list of contiguous observations observed.\n",
    "\n",
    "While this seems overly simplistic, we can think of it as a basic form of machine translation. This task requires the network to remember blocks of contiguous observations and demonstrates the LSTM's ability to encode temporal information in low dimensions. We will achieve this using an encoder-decoder sequence-to-sequence model, which is the state of the art architecture for NMT.\n",
    "\n",
    "**Input => Output**\n",
    "```\n",
    "[86, 81, 88, 1, 23] => [86, 81]\n",
    "[78, 64, 7, 99, 23] => [78, 64]\n",
    "[2, 36, 73, 26, 27] => [2, 36]\n",
    "...\n",
    "[13, 13, 53, 40, 64] => [13, 13]\n",
    "```\n",
    "\n",
    "## Architecture\n",
    "![enc-dec-2](img\\enc-dec-2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.tslibs.offsets as liboffsets\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as libalgos, ops as libops\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.interval import (\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import internals as libinternals\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, reduction,\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib, writers as libwriters\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/sklearn/utils/__init__.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/optimize/_trlib/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._trlib import TRLIBQuadraticSubproblem\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/optimize/_numdiff.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n",
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n"
     ]
    }
   ],
   "source": [
    "# This cell is runnable!\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate datasets\n",
    "\n",
    "Since it is not important what the IDs themselves are, we will just generate them randomly. We will arbitrarily set the following parameters:\n",
    "\n",
    "- *input_dim* = 100: number of possible IDs, 100 means range is 0-99\n",
    "- *n_in* = 5: number of words in each input sequence\n",
    "- *n_out* = 2: number of words to echo back (output)\n",
    "\n",
    "We set aside 20% of the data for testing and use the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample X:\n",
      "[[40 34 57 60 27]\n",
      " [65 93 17 47 81]\n",
      " [13 29 74 47 89]\n",
      " [77 17 92 19  2]\n",
      " [48 75 74 19 14]]\n",
      "Sample y:\n",
      "[[40 34]\n",
      " [65 93]\n",
      " [13 29]\n",
      " [77 17]\n",
      " [48 75]]\n"
     ]
    }
   ],
   "source": [
    "# This cell is runnable!\n",
    "\n",
    "def generate_sequence(input_dim, num_seq, length):\n",
    "    return np.random.randint(input_dim, size=(num_seq, length))\n",
    "\n",
    "def get_data(input_dim, n_in, n_out, size=10000):\n",
    "    X = generate_sequence(input_dim, size, n_in)\n",
    "    y = X[:,:n_out]\n",
    "    return X, y\n",
    "\n",
    "input_dim = 100\n",
    "n_in = 5\n",
    "n_out = 2\n",
    "X, y = get_data(input_dim, n_in, n_out)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print \"Sample X:\\n\", X_train[:5]\n",
    "print \"Sample y:\\n\", y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed sequence\n",
    "* Before shape: [*n_in*]\n",
    "* After shape: [*n_in* x *input_dim*]\n",
    "\n",
    "In the previous lesson, we learned about word embeddings. A word embedding is a fixed dimensional vector that represents one element of the input sequence. If our IDs represented words in a large vocabulary, we would want to use pre-trained word embeddings such as word2vec/GloVe, or initialize them to random vectors and let our model train them.\n",
    "\n",
    "However, since our vocabulary is small (IDs from 0-99), here we will use one-hot vectors. This means we represent ID $n$ with a vector that is 1 at position $n$ and 0 everywhere else.\n",
    "\n",
    "```\n",
    "[0,2,1] -> [[1., 0., 0.],\n",
    "            [0., 0., 1.],\n",
    "            [0., 1., 0.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_embedding_random(ids, vocab_size, embedding_size):\n",
    "    with tf.variable_scope('word_embedding'):\n",
    "        # If GloVe or word2vec, C would be need to be passed in instead of declared as a variable\n",
    "        C = tf.get_variable('C', [vocab_size, embedding_size], initializer=tf.random_normal_initializer())\n",
    "        return tf.nn.embedding_lookup(C, ids)\n",
    "                        \n",
    "def to_embedding_one_hot(ids, vocab_size):\n",
    "    return tf.one_hot(ids, vocab_size)\n",
    "\n",
    "inputs = to_embedding_one_hot(X_train, input_dim)\n",
    "outputs = to_embedding_one_hot(y_train, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "### Encoder\n",
    "* Before shape: [*n_in* x *input_dim*]\n",
    "* After shape: [1 x *hidden_dim*]\n",
    "\n",
    "After the embedding step, our input is *n_in* vectors of length *input_dim*. We will use an LSTM encoder to *encode* all the information from the input sequence into a single vector of length *hidden_dim*.\n",
    "\n",
    "Remember that the LSTM keeps track of its internal memory state $C_t$. We will feed our entire input $w_1, w_2, \\dots w_{n_{in}}$ into an LSTM and extract the LSTM state at the final step, $C_{n_{in}}$, as our encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 150\n",
    "encoder_cell = tf.nn.rnn_cell.LSTMCell(hidden_dim)\n",
    "encoder_h, encoder_c_and_h = tf.nn.dynamic_rnn(\n",
    "    encoder_cell,\n",
    "    inputs,\n",
    "    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "* Before shape: [1 x *hidden_dim*]\n",
    "* After shape: [*n_out* x *hidden_dim*]\n",
    "\n",
    "Now we need to decode our encoding into a sequence of *n_out* IDs. We will run another LSTM for $n_{out}$ time steps and extract the hidden states $h_1 \\dots h_{n_{out}}$ as our outputs. We will simply use the encoder final state as the input at each of the time steps. We also use the encoder final state to initialize the decoder LSTM state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy encoder state n_out times\n",
    "decoder_inputs = tf.tile(tf.expand_dims(encoder_c_and_h.h, 1), (1, n_out, 1))\n",
    "\n",
    "# Construct decoder LSTM with encoder state as initial state\n",
    "decoder_cell = tf.nn.rnn_cell.LSTMCell(hidden_dim)\n",
    "decoder_h, decoder_c_and_h = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, \n",
    "    decoder_inputs, \n",
    "    initial_state=encoder_c_and_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output layer\n",
    "* Before shape: [*n_out* x *hidden_dim*]\n",
    "* After shape: [*n_out* x *input_dim*]\n",
    "\n",
    "After the decoding, all we need to do is use a feed-forward layer (like the MLP) to transform our outputs from *hidden_dim* to *input_dim* dimensions. We now have a sequence of word embeddings again! We then apply a softmax over the word embedding dimension to get a probability distribution over the IDs, and predict the ID with the highest probability for each element in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(decoder_h, input_dim)\n",
    "predictions = tf.argmax(tf.nn.softmax(logits), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "We will use cross entropy loss to train our model. We use the Adam optimizer, which is a variant of stochastic gradient descent that uses a dynamic learning rate.\n",
    "\n",
    "Above, we built our model graph -- `model_outputs` represents the final output of our model. In order to train it, we now need to define a loss and optimizer. Tensorflow optimizers automatically compute gradients for a loss and apply gradients to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=outputs))\n",
    "optimizer = tf.train.AdamOptimizer(eta).minimize(cost) # eta is learning rate\n",
    "\n",
    "# Run the training operation\n",
    "for i in range(iters):\n",
    "    _, loss, predictions = self.sess.run([optimizer, cost, predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the complete code for a `BasicEncoderDecoder` class, followed by a simple example script for how to use it. Like a `scikit-learn` model, we first create a model object with hyperparameters, then directly call `fit(X,y)` and `predict(X,y)` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is runnable!\n",
    "\n",
    "class BasicEncoderDecoder(object):\n",
    "    \"\"\"\n",
    "    Adapted from Chris Potts's CS224U model classes (https://github.com/cgpotts/cs224u)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    embed_dim : int\n",
    "        Dimensionality of embeddings (if one-hot, size of vocab).\n",
    "    cell_class : tf.nn.rnn_cell class\n",
    "       The default is `tf.nn.rnn_cell.LSTMCell`. Other prominent options:\n",
    "       `tf.nn.rnn_cell.BasicRNNCell`, and `tf.nn.rnn_cell.GRUCell`.\n",
    "    hidden_dim : int\n",
    "        Dimensionality of hidden layers.\n",
    "    hidden_activation : tf.nn activation\n",
    "       E.g., tf.nn.relu, tf.nn.relu, tf.nn.selu.\n",
    "    max_iter : int\n",
    "    eta : float\n",
    "        Learning rate\n",
    "    tol : float\n",
    "        Stopping criterion for the loss.\n",
    "    display_progress : int\n",
    "        For value i, progress is printed every ith iteration.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 embed_dim=100,\n",
    "                 cell_class=tf.nn.rnn_cell.LSTMCell,\n",
    "                 hidden_dim=150, \n",
    "                 hidden_activation=tf.nn.tanh,\n",
    "                 batch_size=200, \n",
    "                 eta=0.01, \n",
    "                 tol=1e-4, \n",
    "                 display_progress=1):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.cell_class = cell_class\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.batch_size = batch_size\n",
    "        self.eta = eta\n",
    "        self.tol = tol\n",
    "        self.display_progress = display_progress\n",
    "    \n",
    "    def _encoder(self, encoder_inputs):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            # Declaring LSTM cell\n",
    "            encoder_cell = self.cell_class(\n",
    "                self.hidden_dim, activation=self.hidden_activation)\n",
    "            # Declaring RNN with above cell\n",
    "            _, encoder_state = tf.nn.dynamic_rnn(\n",
    "                encoder_cell,\n",
    "                encoder_inputs,\n",
    "                dtype=tf.float32)\n",
    "            decoder_inputs = tf.tile(tf.expand_dims(encoder_state.h, 1), (1, self.trg_len, 1))\n",
    "            return encoder_state, decoder_inputs\n",
    "            \n",
    "    def _decoder(self, encoder_state, decoder_inputs):\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            decoder_cell = self.cell_class(\n",
    "                self.hidden_dim, activation=self.hidden_activation)\n",
    "            decoder_outputs, _ = tf.nn.dynamic_rnn(\n",
    "                decoder_cell, \n",
    "                decoder_inputs, \n",
    "                initial_state=encoder_state)\n",
    "            # Dense layer to get logits of size embed_dim\n",
    "            return tf.layers.dense(decoder_outputs, self.embed_dim)\n",
    "        \n",
    "    def _enc_dec_body(self, inputs):\n",
    "        encoder_state, decoder_inputs = self._encoder(inputs)\n",
    "        return self._decoder(encoder_state, decoder_inputs)\n",
    "            \n",
    "    def _to_embedding(self, ids):\n",
    "        # Can alternatively use random, word2vec, or GloVe embeddings\n",
    "        return tf.one_hot(ids, self.embed_dim)\n",
    "    \n",
    "    def fit(self, X, y, max_iter=100, **kwargs):\n",
    "        \"\"\"Standard `fit` method.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : [n x src_len] int\n",
    "        y : [n x trg_len] int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        self.src_len = len(X[0])\n",
    "        self.trg_len = len(y[0]) \n",
    "\n",
    "        # Start the session:\n",
    "        tf.reset_default_graph()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "\n",
    "        # Declare the inputs and outputs\n",
    "        self.src = tf.placeholder(\n",
    "            tf.int32, [None, self.src_len])\n",
    "        self.trg = tf.placeholder(\n",
    "            tf.int32, shape=[None, self.trg_len])\n",
    "        inputs = self._to_embedding(self.src)\n",
    "        outputs = self._to_embedding(self.trg)\n",
    "        \n",
    "        # Build the encoder-decoder body.\n",
    "        self.model = self._enc_dec_body(inputs)\n",
    "\n",
    "        # Optimizer set-up:\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits=self.model, labels=outputs))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.eta).minimize(self.cost)\n",
    "        self.pred = tf.argmax(tf.nn.softmax(self.model), axis=2)\n",
    "        self.accuracy = tf.metrics.accuracy(self.trg, self.pred)\n",
    "\n",
    "        # Initialize the session variables:\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.local_variables_initializer()) # Necessary for self.accuracy\n",
    "\n",
    "        # Training, full dataset for each iteration:\n",
    "        for i in range(1, max_iter+1):\n",
    "            loss = 0\n",
    "            acc = []\n",
    "            for X_batch, y_batch in self._batch_iterator(X, y):\n",
    "                _, batch_loss, batch_acc = self.sess.run(\n",
    "                    [self.optimizer, self.cost, self.accuracy],\n",
    "                    feed_dict={\n",
    "                        self.src: X,\n",
    "                        self.trg: y\n",
    "                    })\n",
    "                loss += batch_loss\n",
    "                acc.append(batch_acc[1])\n",
    "            acc = sum(acc)/len(acc)\n",
    "            if loss < self.tol:\n",
    "                self._progressbar(\"stopping with loss < self.tol\", i)\n",
    "                break\n",
    "            else:\n",
    "                self._progressbar(\"loss: {}, accuracy: {}\".format(loss, acc), i)\n",
    "        return self\n",
    "    \n",
    "    def _batch_iterator(self, X, y):\n",
    "        dataset = list(zip(X, y))\n",
    "        random.shuffle(dataset)\n",
    "        for i in range(0, len(dataset), self.batch_size):\n",
    "            batch = dataset[i: i+self.batch_size]\n",
    "            X_batch, y_batch = zip(*batch)\n",
    "            yield X_batch, y_batch\n",
    "    \n",
    "    def _progressbar(self, msg, index):\n",
    "        if self.display_progress and index % self.display_progress == 0:\n",
    "            sys.stderr.write('\\r')\n",
    "            sys.stderr.write('Iter {}: {}'.format(index, msg))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "    def predict(self, X, y=None, report_acc=False):\n",
    "        \"\"\"Return target sequence.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : [n x src_len] int\n",
    "        y (optional) : [n x trg_len] int\n",
    "            Must be passed if report_acc is True\n",
    "        report_acc (optional) : boolean\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        [n x trg_len] int\n",
    "         \n",
    "        OR\n",
    "        \n",
    "        [ \n",
    "            [n x trg_len] int, \n",
    "            float \n",
    "        ]\n",
    "        \"\"\"\n",
    "        if report_acc:\n",
    "            if y is None:\n",
    "                raise ValueError\n",
    "            return self.sess.run(\n",
    "                [self.pred, self.accuracy], feed_dict={self.src: X, self.trg: y})\n",
    "        return self.sess.run([self.pred], feed_dict={self.src: X})[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n",
      "Iter 5: loss: 0.382635515649, accuracy: 0.839400216937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e996a9c73672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                  \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                  display_progress=1)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-bf448ea98a14>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, max_iter, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m                     feed_dict={\n\u001b[1;32m    127\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                     })\n\u001b[1;32m    130\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindywang/miniconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This cell is runnable!\n",
    "\n",
    "# These are the default settings, feel free to change them and see what happens!\n",
    "bed = BasicEncoderDecoder(embed_dim=100,\n",
    "                 cell_class=tf.nn.rnn_cell.LSTMCell,\n",
    "                 hidden_dim=150, \n",
    "                 hidden_activation=tf.nn.tanh,\n",
    "                 batch_size=200, \n",
    "                 eta=0.01, \n",
    "                 tol=1e-4, \n",
    "                 display_progress=1)\n",
    "bed.fit(X_train, y_train, max_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9725975\n"
     ]
    }
   ],
   "source": [
    "# This cell is runnable!\n",
    "\n",
    "preds, acc = bed.predict(X_test, y_test, report_acc=True)\n",
    "print \"Accuracy: \", acc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This is the end of our RNN + LSTM crash course! Today we discussed RNNs, a type of neural network that can model sequential data. We introduced the mathematical and conceptual ideas behind LSTMs, a type of RNN that specializes in long-range memory tasks. We also implemented a basic LSTM encoder-decoder model in Tensorflow and trained it to echo back a partial list of observed data.\n",
    "\n",
    "## Further reading\n",
    "\n",
    "There is much more to be learned on all the topics mentioned in this tutorial. Here is an incomplete list of related topics and useful articles:\n",
    "- Visual explanation of LSTMs and variants (including GRU) http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (**highly recommended!**)\n",
    "- Neural network math (including backpropagation) http://adventuresinmachinelearning.com/neural-networks-tutorial\n",
    "- Sequence to sequence learning with \"teacher forcing\" https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "    - \"Teacher forcing\" means to output one token at a time (instead of all at once) and to use the network's prior outputs as inputs to the decoder. This is how most current NMT models work!\n",
    "- Tensorflow RNN documentation https://www.tensorflow.org/api_guides/python/contrib.rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- \"Fundamentals of Deep Learning – Introduction to Recurrent Neural Networks\" https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/\n",
    "- \"Neural Networks Tutorial – A Pathway to Deep Learning\" http://adventuresinmachinelearning.com/neural-networks-tutorial\n",
    "- \"Understanding LSTM Networks\" http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (**highly recommended!**)\n",
    "- \"LSTM and GRU -- Formula Summary\" https://isaacchanghau.github.io/post/lstm-gru-formula/\n",
    "- \"Recurrent neural networks and LSTM tutorial in Python and TensorFlow\" http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/\n",
    "- \"How to use an Encoder-Decoder LSTM to Echo Sequences of Random Integers\" https://machinelearningmastery.com/how-to-use-an-encoder-decoder-lstm-to-echo-sequences-of-random-integers/\n",
    "- CS224D Lecture Notes 4 https://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
